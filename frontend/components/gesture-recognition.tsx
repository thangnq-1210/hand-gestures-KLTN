"use client"

import { useRef, useState, useCallback, useEffect } from "react"
import { Button } from "@/components/ui/button"
import { Card } from "@/components/ui/card"
import { AlertCircle, CheckCircle2, Info, Camera, Lock } from "lucide-react"
import TextToSpeech from "./text-to-speech"
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs"
import { Slider } from "@/components/ui/slider"
import { Switch } from "@/components/ui/switch"
import { Label } from "@/components/ui/label"
import { Alert, AlertDescription } from "@/components/ui/alert"

interface GestureRecognitionProps {
  onGestureDetected: (gesture: string, text: string, confidence: number) => void
}

type RecognitionStatus =
  | "idle"
  | "detecting"
  | "no_hand"
  | "hand_obscured"
  | "ready"
  | "high_confidence"
  | "permission_denied"
  | "not_supported"

export default function GestureRecognition({ onGestureDetected }: GestureRecognitionProps) {
  const videoRef = useRef<HTMLVideoElement>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const [isLoading, setIsLoading] = useState(false)
  const [currentResult, setCurrentResult] = useState<{
    gesture: string
    text: string
    confidence: number
  } | null>(null)
  const [isStreamActive, setIsStreamActive] = useState(false)
  const [cameraError, setCameraError] = useState<string | null>(null)

  const [confidenceThreshold, setConfidenceThreshold] = useState(0.6)
  const [oneTabMode, setOneTabMode] = useState(false)
  const [autoSpeak, setAutoSpeak] = useState(false)
  const [dataCollectionMode, setDataCollectionMode] = useState(false)
  const [selectedGestureForCollection, setSelectedGestureForCollection] = useState("0")
  const [collectedSamples, setCollectedSamples] = useState<{ [key: string]: number }>({})
  const [recognitionStatus, setRecognitionStatus] = useState<RecognitionStatus>("idle")

  // tr·∫°ng th√°i & timer cho th√¥ng b√°o + ƒë·ªçc sau 5s
  const [pendingSpeech, setPendingSpeech] = useState(false)
  const speechTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const lastSpokenGestureRef = useRef<string | null>(null)
  // dem nguoc
  const [countdown, setCountdown] = useState<number | null>(null)
  const countdownIntervalRef = useRef<NodeJS.Timeout | null>(null)

  // G·ªçi API TTS backend ƒë·ªÉ ph√°t ti·∫øng Vi·ªát chu·∫©n
  const playServerTTS = useCallback(async (text: string) => {
    try {
      if (!text.trim()) return

      const res = await fetch("http://127.0.0.1:8000/tts/vi", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
      })

      if (!res.ok) {
        console.error("TTS API error:", res.status, await res.text())
        return
      }

      const blob = await res.blob()
      const url = URL.createObjectURL(blob)
      const audio = new Audio(url)

      audio.onended = () => {
        URL.revokeObjectURL(url)
      }
      audio.onerror = (e) => {
        console.error("Error playing TTS audio:", e)
        URL.revokeObjectURL(url)
      }

      await audio.play()
    } catch (err) {
      console.error("playServerTTS error:", err)
    }
  }, [])


  const defaultGestures = [
    { id: "0", name: "C·ª≠ ch·ªâ 0", text: "Xin ch√†o" },
    { id: "1", name: "C·ª≠ ch·ªâ 1", text: "T√¥i c·∫ßn gi√∫p ƒë·ª°" },
    { id: "2", name: "C·ª≠ ch·ªâ 2", text: "V√¢ng" },
    { id: "3", name: "C·ª≠ ch·ªâ 3", text: "Kh√¥ng" },
    { id: "4", name: "C·ª≠ ch·ªâ 4", text: "C·∫£m ∆°n" },
    { id: "5", name: "C·ª≠ ch·ªâ 5", text: "T√¥i ƒëang ƒëau" },
  ]

  // d·ªçn d·∫πp timer khi unmount
  useEffect(() => {
    return () => {
      if (speechTimeoutRef.current) {
        clearTimeout(speechTimeoutRef.current)
      }
      if (countdownIntervalRef.current) {
        clearInterval(countdownIntervalRef.current)
      }
    }
  }, [])

  const initializeCamera = useCallback(async () => {
    try {
      setCameraError(null)
      setRecognitionStatus("idle")

      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error("Tr√¨nh duy·ªát c·ªßa b·∫°n kh√¥ng h·ªó tr·ª£ truy c·∫≠p camera")
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user", width: { ideal: 640 }, height: { ideal: 480 } },
        audio: false,
      })

      if (videoRef.current) {
        videoRef.current.srcObject = stream
        setIsStreamActive(true)
        setRecognitionStatus("ready")
      }
    } catch (error: unknown) {
      setIsStreamActive(false)
      let errorMessage = "Kh√¥ng th·ªÉ truy c·∫≠p camera"

      if (error instanceof DOMException) {
        if (error.name === "NotAllowedError" || error.name === "PermissionDeniedError") {
          errorMessage = "Quy·ªÅn truy c·∫≠p camera b·ªã t·ª´ ch·ªëi. Vui l√≤ng c·∫•p quy·ªÅn camera trong c√†i ƒë·∫∑t tr√¨nh duy·ªát."
          setRecognitionStatus("permission_denied")
        } else if (error.name === "NotFoundError" || error.name === "DevicesNotFoundError") {
          errorMessage = "Kh√¥ng t√¨m th·∫•y camera. Vui l√≤ng ki·ªÉm tra xem camera c√≥ ƒë∆∞·ª£c k·∫øt n·ªëi kh√¥ng."
          setRecognitionStatus("not_supported")
        } else if (error.name === "NotReadableError") {
          errorMessage = "Camera ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng b·ªüi ·ª©ng d·ª•ng kh√°c. Vui l√≤ng ƒë√≥ng ·ª©ng d·ª•ng ƒë√≥."
          setRecognitionStatus("not_supported")
        }
      } else if (error instanceof Error) {
        errorMessage = error.message
      }

      console.error("[v0] Camera initialization error:", error)
      setCameraError(errorMessage)
    }
  }, [])

  const stopCamera = useCallback(() => {
    // D·ª´ng stream n·∫øu ƒëang b·∫≠t
    if (videoRef.current && videoRef.current.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream
      stream.getTracks().forEach((track) => track.stop())
      videoRef.current.srcObject = null
    }

    setIsStreamActive(false)
    setRecognitionStatus("idle")

    // Xo√° k·∫øt qu·∫£ hi·ªán t·∫°i (tu·ª≥ b·∫°n, c√≥ th·ªÉ gi·ªØ l·∫°i n·∫øu mu·ªën)
    setCurrentResult(null)

    // Hu·ª∑ c√°c timer ƒë·∫øm ng∆∞·ª£c / auto speak
    if (speechTimeoutRef.current) {
      clearTimeout(speechTimeoutRef.current)
      speechTimeoutRef.current = null
    }
    if (countdownIntervalRef.current) {
      clearInterval(countdownIntervalRef.current)
      countdownIntervalRef.current = null
    }
    setPendingSpeech(false)
    setCountdown(null)
  }, [])

  const captureAndPredict = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current) return

    try {
      setIsLoading(true)
      setRecognitionStatus("detecting")

      const ctx = canvasRef.current.getContext("2d")
      if (!ctx) return

      canvasRef.current.width = videoRef.current.videoWidth
      canvasRef.current.height = videoRef.current.videoHeight
      ctx.drawImage(videoRef.current, 0, 0)

      const base64Image = canvasRef.current.toDataURL("image/jpeg", 0.9)

      const response = await fetch("/api/gesture/predict-base64", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ image: base64Image }),
      })

      if (!response.ok) {
        const msg = await response.text()
        console.error("API /api/gesture/predict-base64 error:", response.status, msg)
        throw new Error("API request failed")
      }

      const data = await response.json()
      // üëá th√™m has_hand ·ªü ƒë√¢y (backend ph·∫£i tr·∫£ v·ªÅ)
      const { gesture, confidence, text, has_hand } = data

      // 1) Kh√¥ng c√≥ tay trong khung -> hi·ªán ƒë√∫ng c√¢u b·∫°n mu·ªën
      if (has_hand === false || gesture === "no_hand") {
        setRecognitionStatus("no_hand")
        setCurrentResult({
          gesture: "-",                               // kh√¥ng hi·ªÉn th·ªã l·ªõp
          text: "Vui l√≤ng gi∆° tay v√†o camera",        // üëà th√¥ng b√°o
          confidence: 0,                              // thanh % = 0
        })

        // t·∫Øt m·ªçi h·∫πn gi·ªù ƒë·ªçc, t·∫Øt th√¥ng b√°o
        if (speechTimeoutRef.current) clearTimeout(speechTimeoutRef.current)
        setPendingSpeech(false)
        return
      }

      // 2) C√≥ tay nh∆∞ng ƒë·ªô tin c·∫≠y th·∫•p
      if (confidence < confidenceThreshold) {
        setRecognitionStatus("no_hand")
        setCurrentResult({
          gesture: "Kh√¥ng ch·∫Øc ch·∫Øn",
          text: "ƒê·ªô tin c·∫≠y th·∫•p, h√£y gi·ªØ tay r√µ trong khung h√¨nh",
          confidence: confidence || 0,
        })

        if (speechTimeoutRef.current) clearTimeout(speechTimeoutRef.current)
        if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current)
        setPendingSpeech(false)
        setCountdown(null)
        lastSpokenGestureRef.current = null
      } else {
        // nh·∫≠n di·ªán th√†nh c√¥ng
        const effectiveGesture = gesture || "Unknown"
        const effectiveText = text || "Kh√¥ng x√°c ƒë·ªãnh"
        const effectiveConf = confidence || 0

        setRecognitionStatus("high_confidence")
        setCurrentResult({
          gesture: effectiveGesture,
          text: effectiveText,
          confidence: effectiveConf,
        })
        onGestureDetected(effectiveGesture, effectiveText, effectiveConf)

        // üîä ƒê·ªçc t·ª± ƒë·ªông sau 3s n·∫øu autoSpeak b·∫≠t
        if (autoSpeak && !pendingSpeech) {
          const TOTAL_SECONDS = 3

          // hu·ª∑ timer c≈© n·∫øu c√≥
          if (speechTimeoutRef.current) {
            clearTimeout(speechTimeoutRef.current)
          }
          if (countdownIntervalRef.current) {
            clearInterval(countdownIntervalRef.current)
          }

          // b·∫≠t th√¥ng b√°o gi·ªØ tay + set countdown
          setPendingSpeech(true)
          setCountdown(TOTAL_SECONDS)

          // interval ƒë·∫øm ng∆∞·ª£c m·ªói 1 gi√¢y
          countdownIntervalRef.current = setInterval(() => {
            setCountdown((prev) => {
              if (prev === null) return null
              if (prev <= 1) {
                // t·ªõi 0 th√¨ d·ª´ng ƒë·∫øm
                if (countdownIntervalRef.current) {
                  clearInterval(countdownIntervalRef.current)
                  countdownIntervalRef.current = null
                }
                return 0
              }
              return prev - 1
            })
          }, 1000)

          // sau 3 gi√¢y th√¨ ph√°t √¢m
          speechTimeoutRef.current = setTimeout(() => {
            setPendingSpeech(false)
            setCountdown(null)

            // d√πng TTS t·ª´ server, kh√¥ng d√πng speechSynthesis n·ªØa
            void playServerTTS(effectiveText)
          }, TOTAL_SECONDS * 1000)
        } else if (!autoSpeak) {
          // t·∫Øt autoSpeak ‚Üí hu·ª∑ timer v√† reset
          if (speechTimeoutRef.current) clearTimeout(speechTimeoutRef.current)
          if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current)
          setPendingSpeech(false)
          setCountdown(null)
        }

        if (oneTabMode && confidence >= confidenceThreshold) {
          console.log("[v0] One-tap mode enabled, gesture processed automatically")
        }
      }

    } catch (error) {
      console.error("Prediction error:", error)
      setRecognitionStatus("no_hand")
      setCurrentResult({
        gesture: "L·ªói",
        text: "L·ªói khi x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i.",
        confidence: 0,
      })

      if (speechTimeoutRef.current) clearTimeout(speechTimeoutRef.current)
      setPendingSpeech(false)
    } finally {
      setIsLoading(false)
    }
  }, [onGestureDetected, confidenceThreshold, autoSpeak, oneTabMode, pendingSpeech, playServerTTS])

  const handlePrimaryButtonClick = useCallback(() => {
    if (recognitionStatus === "high_confidence") {
      // V·ª´a nh·∫≠n di·ªán xong, gi·ªù mu·ªën nh·∫≠n ti·∫øp c·ª≠ ch·ªâ kh√°c:
      // reset tr·∫°ng th√°i v·ªÅ "ready", xo√° k·∫øt qu·∫£ c≈©, hu·ª∑ timer
      setRecognitionStatus("ready")
      setCurrentResult(null)

      if (speechTimeoutRef.current) {
        clearTimeout(speechTimeoutRef.current)
        speechTimeoutRef.current = null
      }
      if (countdownIntervalRef.current) {
        clearInterval(countdownIntervalRef.current)
        countdownIntervalRef.current = null
      }

      setPendingSpeech(false)
      setCountdown(null)
    } else {
      void captureAndPredict()
    }
  }, [recognitionStatus, captureAndPredict])

  useEffect(() => {
    let interval: NodeJS.Timeout | null = null

    // üëá khi ƒëang ƒë·∫øm ng∆∞·ª£c (pendingSpeech = true) th√¨ T·∫†M D·ª™NG auto nh·∫≠n di·ªán
    if (isStreamActive && !dataCollectionMode && !pendingSpeech && recognitionStatus !== "high_confidence") {
      interval = setInterval(() => {
        captureAndPredict()
      }, 2000)
    }

    return () => {
      if (interval) clearInterval(interval)
    }
  }, [isStreamActive, captureAndPredict, dataCollectionMode, pendingSpeech, recognitionStatus])

  const handleCollectSample = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current) return

    const ctx = canvasRef.current.getContext("2d")
    if (!ctx) return

    canvasRef.current.width = videoRef.current.videoWidth
    canvasRef.current.height = videoRef.current.videoHeight
    ctx.drawImage(videoRef.current, 0, 0)

    const base64Image = canvasRef.current.toDataURL("image/jpeg", 0.9)

    setCollectedSamples((prev) => ({
      ...prev,
      [selectedGestureForCollection]: (prev[selectedGestureForCollection] || 0) + 1,
    }))

    localStorage.setItem(
      `gesture_samples_${selectedGestureForCollection}`,
      JSON.stringify({
        count: (collectedSamples[selectedGestureForCollection] || 0) + 1,
        samples: [base64Image],
        timestamp: new Date(),
      }),
    )
  }, [selectedGestureForCollection, collectedSamples])

  const getStatusIcon = () => {
    switch (recognitionStatus) {
      case "ready":
        return <CheckCircle2 className="w-5 h-5 text-green-500" />
      case "detecting":
        return <AlertCircle className="w-5 h-5 text-blue-500 animate-pulse" />
      case "no_hand":
        return <AlertCircle className="w-5 h-5 text-yellow-500" />
      case "high_confidence":
        return <CheckCircle2 className="w-5 h-5 text-green-500" />
      case "permission_denied":
        return <Lock className="w-5 h-5 text-red-500" />
      case "not_supported":
        return <Camera className="w-5 h-5 text-red-500" />
      default:
        return <Info className="w-5 h-5 text-gray-500" />
    }
  }

  const getStatusText = () => {
    switch (recognitionStatus) {
      case "ready":
        return "S·∫µn s√†ng nh·∫≠n di·ªán"
      case "detecting":
        return "ƒêang nh·∫≠n di·ªán..."
      case "no_hand":
        return "Kh√¥ng th·∫•y tay ho·∫∑c ƒë·ªô tin c·∫≠y th·∫•p"
      case "hand_obscured":
        return "Tay b·ªã che khu·∫•t"
      case "high_confidence":
        return "Nh·∫≠n di·ªán th√†nh c√¥ng"
      case "permission_denied":
        return "Quy·ªÅn truy c·∫≠p b·ªã t·ª´ ch·ªëi"
      case "not_supported":
        return "Camera kh√¥ng kh·∫£ d·ª•ng"
      default:
        return "Ch·∫ø ƒë·ªô nh√†n r·ªói"
    }
  }

  return (
    <div className="space-y-6">
      {/* Camera Section */}
      <div className="space-y-4">
        <div className="flex items-center justify-between">
          <h2 className="text-2xl font-bold text-primary">Camera Nh·∫≠n Di·ªán</h2>
          <div className="flex items-center gap-2 text-sm">
            {getStatusIcon()}
            <span className="text-muted-foreground">{getStatusText()}</span>
          </div>
        </div>

        {cameraError && (
          <Alert variant="destructive" className="border-red-500 bg-red-50 dark:bg-red-950">
            <AlertCircle className="h-4 w-4 text-red-600" />
            <AlertDescription className="text-red-800 dark:text-red-200">{cameraError}</AlertDescription>
          </Alert>
        )}

        {/* Video Feed */}
        <div className="relative w-full bg-black rounded-lg overflow-hidden border-2 border-primary/30">
          <video
            ref={videoRef}
            autoPlay
            playsInline
            className="w-full aspect-video object-cover"
            aria-label="Webcam feed for gesture recognition"
          />
          <canvas ref={canvasRef} className="hidden" />

          {!isStreamActive && (
            <div className="absolute inset-0 flex flex-col items-center justify-center bg-black/50 text-white text-center p-4">
              <Camera className="w-12 h-12 mb-4 opacity-50" />
              <p className="text-lg font-semibold">Camera ch∆∞a kh·ªüi ƒë·ªông</p>
              {cameraError && <p className="text-sm mt-2 text-gray-300">B·∫•m n√∫t d∆∞·ªõi ƒë·ªÉ c·∫•p quy·ªÅn camera</p>}
            </div>
          )}
        </div>

        {/* Camera Controls */}
        <div className="flex gap-3 flex-wrap">
          {!isStreamActive ? (
            <Button
              onClick={initializeCamera}
              size="lg"
              className="flex-1 bg-primary hover:bg-primary/90 text-white font-bold text-lg py-6"
              disabled={cameraError !== null && recognitionStatus === "not_supported"}
            >
              <Camera className="w-5 h-5 mr-2" />
              Kh·ªüi ƒë·ªông camera
            </Button>
          ) : (
            <>
              {/* <Button
                onClick={captureAndPredict}
                disabled={isLoading}
                size="lg"
                className="flex-1 bg-accent hover:bg-accent/90 text-white font-bold text-lg py-6"
                aria-label={isLoading ? "Processing gesture..." : "Detect gesture"}
              >
                {isLoading ? "ƒêang x·ª≠ l√Ω..." : "ƒêang nh·∫≠n di·ªán..."}
              </Button> */}
              <Button
                onClick={handlePrimaryButtonClick}
                disabled={isLoading}
                size="lg"
                className={`flex-1 font-bold text-lg py-6 text-white transition-colors
                  ${recognitionStatus === "high_confidence"
                    ? "bg-primary hover:bg-primary/90"       // üëâ gi·ªëng n√∫t Kh·ªüi ƒë·ªông camera
                    : "bg-accent hover:bg-accent/90"         // üëâ tr·∫°ng th√°i b√¨nh th∆∞·ªùng
                  }`}
                aria-label={
                  isLoading
                    ? "Processing gesture..."
                    : recognitionStatus === "high_confidence"
                      ? "Continue detection"
                      : "Detect gesture"
                }
              >
                {isLoading
                  ? "ƒêang x·ª≠ l√Ω..."
                  : recognitionStatus === "high_confidence"
                    ? "Ti·∫øp t·ª•c nh·∫≠n di·ªán"
                    : "ƒêang nh·∫≠n di·ªán..."}
              </Button>


              <Button
                onClick={stopCamera}
                variant="outline"
                size="lg"
                className="px-6 py-6 font-bold text-lg text-white-600 border-red-600 hover:bg-red-50 hover:text-white-600 dark:hover:bg-red-900/30"
              >
                T·∫Øt camera
              </Button>
            </>
          )}
        </div>
      </div>

      {/* Result Display */}
      {currentResult && !dataCollectionMode && (
        <div className="space-y-4">
          <h3 className="text-xl font-bold text-primary">K·∫øt Qu·∫£ Nh·∫≠n Di·ªán</h3>

          <Card className="bg-primary/5 border-2 border-primary/30 p-6 space-y-4">
            <div className="flex justify-between items-center">
              <span className="text-lg font-semibold text-muted-foreground">C·ª≠ Ch·ªâ:</span>
              <span className="text-2xl font-bold text-primary">{currentResult.gesture}</span>
            </div>

            <div className="space-y-2">
              <div className="flex justify-between items-center">
                <span className="text-lg font-semibold text-muted-foreground">ƒê·ªô Tin C·∫≠y:</span>
                <span className="text-xl font-bold text-accent">
                  {(currentResult.confidence * 100).toFixed(1)}%
                </span>
              </div>

              <div className="w-full h-3 bg-muted rounded-full overflow-hidden border border-border">
                <div
                  className="h-full bg-gradient-to-r from-secondary to-accent transition-all duration-300"
                  style={{ width: `${currentResult.confidence * 100}%` }}
                />
              </div>
            </div>

            <div className="space-y-2">
              <span className="text-lg font-semibold text-muted-foreground block">VƒÉn B·∫£n:</span>
              <div className="text-3xl font-bold text-primary text-center bg-primary/10 p-4 rounded-lg border border-primary/20">
                {currentResult.text}
              </div>
            </div>

            {/* üîî Th√¥ng b√°o gi·ªØ tay + t·ª± n√≥i sau 10s */}
            {pendingSpeech && (
              <p className="mt-2 text-sm font-semibold text-amber-500 text-center">
                H√£y gi·ªØ v·ªã tr√≠ tay c·ªßa b·∫°n trong{" "}
                <span className="font-bold">{countdown ?? 0}</span> gi√¢y, h·ªá th·ªëng s·∫Ω t·ª± ph√°t √¢m...
              </p>
            )}

            <TextToSpeech text={currentResult.text} />
          </Card>
        </div>
      )}

      <Tabs defaultValue="settings" className="w-full">
        <TabsList className="grid w-full grid-cols-2">
          <TabsTrigger value="settings">C√†i ƒê·∫∑t</TabsTrigger>
          <TabsTrigger value="collection">Thu Th·∫≠p D·ªØ Li·ªáu</TabsTrigger>
        </TabsList>

        <TabsContent value="settings" className="space-y-4">
          <Card className="border-2 border-secondary/20 p-6 space-y-6">
            {/* Confidence Threshold */}
            <div className="space-y-3">
              <div className="flex justify-between items-center">
                <Label className="text-base font-semibold">Ng∆∞·ª°ng ƒê·ªô Tin C·∫≠y</Label>
                <span className="text-lg font-bold text-primary">
                  {(confidenceThreshold * 100).toFixed(0)}%
                </span>
              </div>
              <Slider
                value={[confidenceThreshold]}
                onValueChange={(value: number[]) => setConfidenceThreshold(value[0])}
                min={0.3}
                max={0.95}
                step={0.05}
                className="w-full"
              />
              <p className="text-sm text-muted-foreground">
                Ch·ªâ ch·∫•p nh·∫≠n c·ª≠ ch·ªâ c√≥ ƒë·ªô tin c·∫≠y cao h∆°n ng∆∞·ª°ng n√†y
              </p>
            </div>

            {/* One-Tap Mode */}
            <div className="flex items-center justify-between p-4 bg-secondary/10 rounded-lg border border-secondary/20">
              <div className="space-y-1">
                <Label className="text-base font-semibold">Ch·∫ø ƒê·ªô 1 Ch·∫°m</Label>
                <p className="text-sm text-muted-foreground">T·ª± ƒë·ªông x·ª≠ l√Ω c·ª≠ ch·ªâ m√† kh√¥ng c·∫ßn b·∫•m n√∫t</p>
              </div>
              <Switch checked={oneTabMode} onCheckedChange={setOneTabMode} />
            </div>

            {/* Auto-Speak */}
            <div className="flex items-center justify-between p-4 bg-secondary/10 rounded-lg border border-secondary/20">
              <div className="space-y-1">
                <Label className="text-base font-semibold">ƒê·ªçc T·ª± ƒê·ªông</Label>
                <p className="text-sm text-muted-foreground">
                  Khi b·∫≠t, h·ªá th·ªëng s·∫Ω hi·ªÉn th·ªã th√¥ng b√°o gi·ªØ tay v√† t·ª± ƒë·ªçc sau 3 gi√¢y
                </p>
              </div>
              <Switch checked={autoSpeak} onCheckedChange={setAutoSpeak} />
            </div>
          </Card>
        </TabsContent>

        <TabsContent value="collection" className="space-y-4">
          <Card className="border-2 border-accent/20 p-6 space-y-6">
            {!dataCollectionMode ? (
              <>
                <Alert>
                  <Info className="h-4 w-4" />
                  <AlertDescription>
                    Ch·∫ø ƒë·ªô thu th·∫≠p d·ªØ li·ªáu cho ph√©p b·∫°n ghi l·∫°i c√°c m·∫´u c·ª≠ ch·ªâ ƒë·ªÉ hu·∫•n luy·ªán model.
                  </AlertDescription>
                </Alert>
                <Button
                  onClick={() => setDataCollectionMode(true)}
                  className="w-full bg-accent hover:bg-accent/90 text-white font-bold py-6"
                >
                  B·∫≠t Ch·∫ø ƒê·ªô Thu Th·∫≠p D·ªØ Li·ªáu
                </Button>
              </>
            ) : (
              <>
                <div className="space-y-3">
                  <Label className="text-base font-semibold">Ch·ªçn C·ª≠ Ch·ªâ ƒê·ªÉ Ghi D·ªØ Li·ªáu</Label>
                  <div className="grid grid-cols-2 gap-2">
                    {defaultGestures.map((gesture) => (
                      <Button
                        key={gesture.id}
                        variant={selectedGestureForCollection === gesture.id ? "default" : "outline"}
                        onClick={() => setSelectedGestureForCollection(gesture.id)}
                        className="flex flex-col items-center gap-2 py-4"
                      >
                        <span className="text-lg font-bold">{gesture.id}</span>
                        <span className="text-xs">{collectedSamples[gesture.id] || 0} m·∫´u</span>
                      </Button>
                    ))}
                  </div>
                </div>

                <div className="space-y-3">
                  <p className="text-sm text-muted-foreground">
                    Gi∆° c·ª≠ ch·ªâ "{selectedGestureForCollection}" r·ªìi b·∫•m "L∆∞u M·∫´u" ƒë·ªÉ ghi l·∫°i
                  </p>
                  <Button
                    onClick={handleCollectSample}
                    className="w-full bg-accent hover:bg-accent/90 text-white font-bold py-6"
                  >
                    L∆∞u M·∫´u
                  </Button>

                  <Button onClick={() => setDataCollectionMode(false)} variant="outline" className="w-full">
                    T·∫Øt Ch·∫ø ƒê·ªô Thu Th·∫≠p
                  </Button>
                </div>

                <div className="grid grid-cols-3 gap-2">
                  {defaultGestures.map((gesture) => (
                    <div
                      key={gesture.id}
                      className="text-center p-3 bg-primary/5 rounded-lg border border-primary/20"
                    >
                      <p className="text-lg font-bold text-primary">{gesture.id}</p>
                      <p className="text-2xl font-bold text-accent">
                        {collectedSamples[gesture.id] || 0}
                      </p>
                      <p className="text-xs text-muted-foreground">m·∫´u</p>
                    </div>
                  ))}
                </div>
              </>
            )}
          </Card>
        </TabsContent>
      </Tabs>
    </div>
  )
}
